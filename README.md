# TMMLU+ Leaderboard ðŸ‡¹ðŸ‡¼

[![GitHub Pages](https://img.shields.io/badge/GitHub%20Pages-Live-brightgreen)](https://muhammadsaqlainaslam.github.io/tmmlu-leaderboard/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ðŸ“Œ About TMMLU+
**TMMLU+** (Traditional Chinese Massive Multitask Language Understanding) is an advanced benchmark designed to evaluate Large Language Models (LLMs) within the linguistic and cultural context of **Taiwan**.

The benchmark covers **66 subjects** including STEM, Social Sciences, Humanities, and local professional certifications, providing a rigorous standard for Traditional Chinese NLP evaluation.

## ðŸ“Š Live Leaderboard Features
- **Overall Rankings:** Automated sorting by mean accuracy.
- **Dynamic Visualizations:** Discipline-specific Radar and Bar charts.
- **Hierarchical Drill-down:** Expand models to see Major Disciplines, and expand those to see individual subject scores.
- **Search Functionality:** Real-time filtering to find specific models.
- **Integrated General Tasks:** Scores for DRCD, TW-RAG, GSM8K, and more.

ðŸ‘‰ **[Access the Leaderboard](https://muhammadsaqlainaslam.github.io/tmmlu-leaderboard/)**

## ðŸ“‚ Repository Structure
```text
â”œâ”€â”€ .github/ISSUE_TEMPLATE/  # Model submission form configuration
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ index.html           # Interactive Frontend (Plotly, PapaParse, Bootstrap)
â”œâ”€â”€ results/
â”‚   â””â”€â”€ benchmark.csv        # Central Data Source
â””â”€â”€ README.md                # Documentation
